{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结合focal loss 函数讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "1.19.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "mnist = np.load(\"mnist.npz\")\n",
    "x_train, y_train, x_test, y_test = mnist['x_train'],mnist['y_train'],mnist['x_test'],mnist['y_test']\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = np.int32(y_train)\n",
    "y_test = np.int32(y_test)\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "y_train = tf.one_hot(y_train,depth=10)\n",
    "y_test = tf.one_hot(y_test,depth=10)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(100).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    inputs = tf.keras.Input(shape=(28,28,1), name='digits')\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(10,activation='softmax', name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #多分类的focal loss 损失函数\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "\n",
    "#     def __init__(self,gamma=2.0,alpha=0.25):\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         super(FocalLoss, self).__init__()\n",
    "\n",
    "#     def call(self,y_true,y_pred):\n",
    "#         y_pred = tf.nn.softmax(y_pred,axis=-1)\n",
    "#         epsilon = tf.keras.backend.epsilon()\n",
    "#         y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)\n",
    "        \n",
    "       \n",
    "#         y_true = tf.cast(y_true,tf.float32)\n",
    "        \n",
    "#         loss = -  y_true * tf.math.pow(1 - y_pred, self.gamma) * tf.math.log(y_pred)\n",
    "        \n",
    "#         loss = tf.math.reduce_sum(loss,axis=1)\n",
    "#         return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FocalLoss(gamma=2.0,alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.nn.softmax(y_pred,axis=-1)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)\n",
    "\n",
    "        y_true = tf.cast(y_true,tf.float32)\n",
    "\n",
    "        loss = -  y_true * tf.math.pow(1 - y_pred, gamma) * tf.math.log(y_pred)\n",
    "\n",
    "        loss = tf.math.reduce_sum(loss,axis=1)\n",
    "        return  loss\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        if batch % 100 == 0:\n",
    "            print(\"...Training: start of batch {}; got learning rate: {}\".format(\n",
    "                batch, tf.keras.backend.get_value(self.model.optimizer._decayed_lr(tf.float32))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MyModel()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.001), #优化器\n",
    "              loss =  FocalLoss(gamma=2.0,alpha=0.25), #损失函数\n",
    "              metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "             ) #评估函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "...Training: start of batch 0; got learning rate: 0.0010000000474974513\n",
      "    100/Unknown - 8s 75ms/step - loss: 1.1538 - categorical_accuracy: 0.7806...Training: start of batch 100; got learning rate: 0.0010000000474974513\n",
      "    200/Unknown - 14s 71ms/step - loss: 1.0860 - categorical_accuracy: 0.8261...Training: start of batch 200; got learning rate: 0.0010000000474974513\n",
      "    300/Unknown - 21s 70ms/step - loss: 1.0510 - categorical_accuracy: 0.8528...Training: start of batch 300; got learning rate: 0.0010000000474974513\n",
      "    400/Unknown - 28s 70ms/step - loss: 1.0273 - categorical_accuracy: 0.8713...Training: start of batch 400; got learning rate: 0.0010000000474974513\n",
      "    500/Unknown - 38s 75ms/step - loss: 1.0136 - categorical_accuracy: 0.8816...Training: start of batch 500; got learning rate: 0.0010000000474974513\n",
      "    600/Unknown - 47s 78ms/step - loss: 1.0005 - categorical_accuracy: 0.8914...Training: start of batch 600; got learning rate: 0.0010000000474974513\n",
      "    700/Unknown - 56s 79ms/step - loss: 0.9911 - categorical_accuracy: 0.8991...Training: start of batch 700; got learning rate: 0.0010000000474974513\n",
      "    800/Unknown - 68s 85ms/step - loss: 0.9837 - categorical_accuracy: 0.9048...Training: start of batch 800; got learning rate: 0.0010000000474974513\n",
      "    900/Unknown - 80s 89ms/step - loss: 0.9768 - categorical_accuracy: 0.9101- 73s 86...Training: start of batch 900; got learning rate: 0.0010000000474974513\n",
      "   1000/Unknown - 88s 88ms/step - loss: 0.9706 - categorical_accuracy: 0.9150...Training: start of batch 1000; got learning rate: 0.0010000000474974513\n",
      "   1100/Unknown - 95s 87ms/step - loss: 0.9656 - categorical_accuracy: 0.9189...Training: start of batch 1100; got learning rate: 0.0010000000474974513\n",
      "   1200/Unknown - 103s 86ms/step - loss: 0.9620 - categorical_accuracy: 0.9216...Training: start of batch 1200; got learning rate: 0.0010000000474974513\n",
      "   1300/Unknown - 110s 85ms/step - loss: 0.9582 - categorical_accuracy: 0.9246...Training: start of batch 1300; got learning rate: 0.0010000000474974513\n",
      "   1400/Unknown - 117s 84ms/step - loss: 0.9548 - categorical_accuracy: 0.9273...Training: start of batch 1400; got learning rate: 0.0010000000474974513\n",
      "   1500/Unknown - 124s 83ms/step - loss: 0.9515 - categorical_accuracy: 0.9298...Training: start of batch 1500; got learning rate: 0.0010000000474974513\n",
      "   1600/Unknown - 132s 82ms/step - loss: 0.9485 - categorical_accuracy: 0.9321...Training: start of batch 1600; got learning rate: 0.0010000000474974513\n",
      "   1700/Unknown - 138s 81ms/step - loss: 0.9460 - categorical_accuracy: 0.9341...Training: start of batch 1700; got learning rate: 0.0010000000474974513\n",
      "   1800/Unknown - 145s 81ms/step - loss: 0.9436 - categorical_accuracy: 0.9360...Training: start of batch 1800; got learning rate: 0.0010000000474974513\n",
      "1875/1875 [==============================] - 153s 82ms/step - loss: 0.9420 - categorical_accuracy: 0.9372 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "...Training: start of batch 0; got learning rate: 0.0010000000474974513\n",
      " 100/1875 [>.............................] - ETA: 2:26 - loss: 0.9007 - categorical_accuracy: 0.9700...Training: start of batch 100; got learning rate: 0.0010000000474974513\n",
      " 200/1875 [==>...........................] - ETA: 2:04 - loss: 0.9023 - categorical_accuracy: 0.9691...Training: start of batch 200; got learning rate: 0.0010000000474974513\n",
      " 300/1875 [===>..........................] - ETA: 1:52 - loss: 0.9015 - categorical_accuracy: 0.9698...Training: start of batch 300; got learning rate: 0.0010000000474974513\n",
      " 400/1875 [=====>........................] - ETA: 1:44 - loss: 0.9018 - categorical_accuracy: 0.9688...Training: start of batch 400; got learning rate: 0.0010000000474974513\n",
      " 500/1875 [=======>......................] - ETA: 1:36 - loss: 0.9006 - categorical_accuracy: 0.9696...Training: start of batch 500; got learning rate: 0.0010000000474974513\n",
      " 600/1875 [========>.....................] - ETA: 1:28 - loss: 0.8996 - categorical_accuracy: 0.9704...Training: start of batch 600; got learning rate: 0.0010000000474974513\n",
      " 700/1875 [==========>...................] - ETA: 1:21 - loss: 0.8987 - categorical_accuracy: 0.9712...Training: start of batch 700; got learning rate: 0.0010000000474974513\n",
      " 800/1875 [===========>..................] - ETA: 1:14 - loss: 0.8974 - categorical_accuracy: 0.9721...Training: start of batch 800; got learning rate: 0.0010000000474974513\n",
      " 900/1875 [=============>................] - ETA: 1:07 - loss: 0.8974 - categorical_accuracy: 0.9721...Training: start of batch 900; got learning rate: 0.0010000000474974513\n",
      "1000/1875 [===============>..............] - ETA: 1:00 - loss: 0.8969 - categorical_accuracy: 0.9725...Training: start of batch 1000; got learning rate: 0.0010000000474974513\n",
      "1100/1875 [================>.............] - ETA: 53s - loss: 0.8968 - categorical_accuracy: 0.9724...Training: start of batch 1100; got learning rate: 0.0010000000474974513\n",
      "1200/1875 [==================>...........] - ETA: 46s - loss: 0.8969 - categorical_accuracy: 0.9724...Training: start of batch 1200; got learning rate: 0.0010000000474974513\n",
      "1300/1875 [===================>..........] - ETA: 39s - loss: 0.8967 - categorical_accuracy: 0.9725...Training: start of batch 1300; got learning rate: 0.0010000000474974513\n",
      "1400/1875 [=====================>........] - ETA: 33s - loss: 0.8962 - categorical_accuracy: 0.9730...Training: start of batch 1400; got learning rate: 0.0010000000474974513\n",
      "1500/1875 [=======================>......] - ETA: 27s - loss: 0.8959 - categorical_accuracy: 0.9732- ETA: 29s - loss: 0.8959 - cate...Training: start of batch 1500; got learning rate: 0.0010000000474974513\n",
      "1600/1875 [========================>.....] - ETA: 20s - loss: 0.8953 - categorical_accuracy: 0.9736...Training: start of batch 1600; got learning rate: 0.0010000000474974513\n",
      "1700/1875 [==========================>...] - ETA: 13s - loss: 0.8947 - categorical_accuracy: 0.9741...Training: start of batch 1700; got learning rate: 0.0010000000474974513\n",
      "1800/1875 [===========================>..] - ETA: 5s - loss: 0.8943 - categorical_accuracy: 0.9744...Training: start of batch 1800; got learning rate: 0.0010000000474974513\n",
      "1875/1875 [==============================] - 154s 82ms/step - loss: 0.8939 - categorical_accuracy: 0.9747 - val_loss: 0.8961 - val_categorical_accuracy: 0.9713\n",
      "Epoch 3/5\n",
      "...Training: start of batch 0; got learning rate: 0.0010000000474974513\n",
      " 100/1875 [>.............................] - ETA: 2:54 - loss: 0.8854 - categorical_accuracy: 0.9812...Training: start of batch 100; got learning rate: 0.0010000000474974513\n",
      " 200/1875 [==>...........................] - ETA: 2:37 - loss: 0.8854 - categorical_accuracy: 0.9814...Training: start of batch 200; got learning rate: 0.0010000000474974513\n",
      " 300/1875 [===>..........................] - ETA: 2:20 - loss: 0.8869 - categorical_accuracy: 0.9804...Training: start of batch 300; got learning rate: 0.0010000000474974513\n",
      " 400/1875 [=====>........................] - ETA: 2:19 - loss: 0.8864 - categorical_accuracy: 0.9809...Training: start of batch 400; got learning rate: 0.0010000000474974513\n",
      " 500/1875 [=======>......................] - ETA: 2:11 - loss: 0.8863 - categorical_accuracy: 0.9809 ETA: 2:...Training: start of batch 500; got learning rate: 0.0010000000474974513\n",
      " 600/1875 [========>.....................] - ETA: 1:59 - loss: 0.8857 - categorical_accuracy: 0.9814...Training: start of batch 600; got learning rate: 0.0010000000474974513\n",
      " 700/1875 [==========>...................] - ETA: 1:46 - loss: 0.8858 - categorical_accuracy: 0.9811...Training: start of batch 700; got learning rate: 0.0010000000474974513\n",
      " 800/1875 [===========>..................] - ETA: 1:34 - loss: 0.8856 - categorical_accuracy: 0.9811 ETA: 1:35 - loss: 0.8856 - categori...Training: start of batch 800; got learning rate: 0.0010000000474974513\n",
      " 900/1875 [=============>................] - ETA: 1:23 - loss: 0.8855 - categorical_accuracy: 0.9813...Training: start of batch 900; got learning rate: 0.0010000000474974513\n",
      "1000/1875 [===============>..............] - ETA: 1:13 - loss: 0.8856 - categorical_accuracy: 0.9811...Training: start of batch 1000; got learning rate: 0.0010000000474974513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100/1875 [================>.............] - ETA: 1:04 - loss: 0.8853 - categorical_accuracy: 0.9813...Training: start of batch 1100; got learning rate: 0.0010000000474974513\n",
      "1200/1875 [==================>...........] - ETA: 55s - loss: 0.8858 - categorical_accuracy: 0.9809...Training: start of batch 1200; got learning rate: 0.0010000000474974513\n",
      "1300/1875 [===================>..........] - ETA: 46s - loss: 0.8858 - categorical_accuracy: 0.9810...Training: start of batch 1300; got learning rate: 0.0010000000474974513\n",
      "1400/1875 [=====================>........] - ETA: 38s - loss: 0.8855 - categorical_accuracy: 0.9812...Training: start of batch 1400; got learning rate: 0.0010000000474974513\n",
      "1500/1875 [=======================>......] - ETA: 29s - loss: 0.8852 - categorical_accuracy: 0.9814...Training: start of batch 1500; got learning rate: 0.0010000000474974513\n",
      "1600/1875 [========================>.....] - ETA: 21s - loss: 0.8849 - categorical_accuracy: 0.9817...Training: start of batch 1600; got learning rate: 0.0010000000474974513\n",
      "1700/1875 [==========================>...] - ETA: 13s - loss: 0.8846 - categorical_accuracy: 0.9820...Training: start of batch 1700; got learning rate: 0.0010000000474974513\n",
      "1800/1875 [===========================>..] - ETA: 5s - loss: 0.8844 - categorical_accuracy: 0.9821...Training: start of batch 1800; got learning rate: 0.0010000000474974513\n",
      "1875/1875 [==============================] - 147s 78ms/step - loss: 0.8843 - categorical_accuracy: 0.9821 - val_loss: 0.8872 - val_categorical_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "...Training: start of batch 0; got learning rate: 0.0010000000474974513\n",
      " 100/1875 [>.............................] - ETA: 2:31 - loss: 0.8813 - categorical_accuracy: 0.9850...Training: start of batch 100; got learning rate: 0.0010000000474974513\n",
      " 200/1875 [==>...........................] - ETA: 2:08 - loss: 0.8836 - categorical_accuracy: 0.9827...Training: start of batch 200; got learning rate: 0.0010000000474974513\n",
      " 300/1875 [===>..........................] - ETA: 1:56 - loss: 0.8834 - categorical_accuracy: 0.9831...Training: start of batch 300; got learning rate: 0.0010000000474974513\n",
      " 400/1875 [=====>........................] - ETA: 1:46 - loss: 0.8824 - categorical_accuracy: 0.9837...Training: start of batch 400; got learning rate: 0.0010000000474974513\n",
      " 500/1875 [=======>......................] - ETA: 1:37 - loss: 0.8821 - categorical_accuracy: 0.9839...Training: start of batch 500; got learning rate: 0.0010000000474974513\n",
      " 600/1875 [========>.....................] - ETA: 1:29 - loss: 0.8822 - categorical_accuracy: 0.9839...Training: start of batch 600; got learning rate: 0.0010000000474974513\n",
      " 700/1875 [==========>...................] - ETA: 1:22 - loss: 0.8827 - categorical_accuracy: 0.9833 ETA: 1:23 - loss: 0.882...Training: start of batch 700; got learning rate: 0.0010000000474974513\n",
      " 800/1875 [===========>..................] - ETA: 1:14 - loss: 0.8821 - categorical_accuracy: 0.9839...Training: start of batch 800; got learning rate: 0.0010000000474974513\n",
      " 900/1875 [=============>................] - ETA: 1:07 - loss: 0.8815 - categorical_accuracy: 0.9844...Training: start of batch 900; got learning rate: 0.0010000000474974513\n",
      "1000/1875 [===============>..............] - ETA: 1:00 - loss: 0.8813 - categorical_accuracy: 0.9846...Training: start of batch 1000; got learning rate: 0.0010000000474974513\n",
      "1100/1875 [================>.............] - ETA: 53s - loss: 0.8815 - categorical_accuracy: 0.9844...Training: start of batch 1100; got learning rate: 0.0010000000474974513\n",
      "1200/1875 [==================>...........] - ETA: 46s - loss: 0.8810 - categorical_accuracy: 0.9848...Training: start of batch 1200; got learning rate: 0.0010000000474974513\n",
      "1300/1875 [===================>..........] - ETA: 39s - loss: 0.8813 - categorical_accuracy: 0.9846...Training: start of batch 1300; got learning rate: 0.0010000000474974513\n",
      "1400/1875 [=====================>........] - ETA: 32s - loss: 0.8814 - categorical_accuracy: 0.9844...Training: start of batch 1400; got learning rate: 0.0010000000474974513\n",
      "1500/1875 [=======================>......] - ETA: 25s - loss: 0.8810 - categorical_accuracy: 0.9848...Training: start of batch 1500; got learning rate: 0.0010000000474974513\n",
      "1600/1875 [========================>.....] - ETA: 18s - loss: 0.8808 - categorical_accuracy: 0.9850...Training: start of batch 1600; got learning rate: 0.0010000000474974513\n",
      "1700/1875 [==========================>...] - ETA: 12s - loss: 0.8808 - categorical_accuracy: 0.9850...Training: start of batch 1700; got learning rate: 0.0010000000474974513\n",
      "1800/1875 [===========================>..] - ETA: 5s - loss: 0.8808 - categorical_accuracy: 0.9849...Training: start of batch 1800; got learning rate: 0.0010000000474974513\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.8805 - categorical_accuracy: 0.9852 - val_loss: 0.8862 - val_categorical_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "...Training: start of batch 0; got learning rate: 0.0010000000474974513\n",
      " 100/1875 [>.............................] - ETA: 2:03 - loss: 0.8768 - categorical_accuracy: 0.9891...Training: start of batch 100; got learning rate: 0.0010000000474974513\n",
      " 200/1875 [==>...........................] - ETA: 1:54 - loss: 0.8784 - categorical_accuracy: 0.9878...Training: start of batch 200; got learning rate: 0.0010000000474974513\n",
      " 300/1875 [===>..........................] - ETA: 1:47 - loss: 0.8783 - categorical_accuracy: 0.9874...Training: start of batch 300; got learning rate: 0.0010000000474974513\n",
      " 400/1875 [=====>........................] - ETA: 1:40 - loss: 0.8786 - categorical_accuracy: 0.9870...Training: start of batch 400; got learning rate: 0.0010000000474974513\n",
      " 500/1875 [=======>......................] - ETA: 1:33 - loss: 0.8782 - categorical_accuracy: 0.9870...Training: start of batch 500; got learning rate: 0.0010000000474974513\n",
      " 600/1875 [========>.....................] - ETA: 1:26 - loss: 0.8783 - categorical_accuracy: 0.9869...Training: start of batch 600; got learning rate: 0.0010000000474974513\n",
      " 700/1875 [==========>...................] - ETA: 1:19 - loss: 0.8785 - categorical_accuracy: 0.9868...Training: start of batch 700; got learning rate: 0.0010000000474974513\n",
      " 800/1875 [===========>..................] - ETA: 1:13 - loss: 0.8783 - categorical_accuracy: 0.9869...Training: start of batch 800; got learning rate: 0.0010000000474974513\n",
      " 900/1875 [=============>................] - ETA: 1:07 - loss: 0.8784 - categorical_accuracy: 0.9868...Training: start of batch 900; got learning rate: 0.0010000000474974513\n",
      "1000/1875 [===============>..............] - ETA: 1:01 - loss: 0.8786 - categorical_accuracy: 0.9865...Training: start of batch 1000; got learning rate: 0.0010000000474974513\n",
      "1100/1875 [================>.............] - ETA: 54s - loss: 0.8784 - categorical_accuracy: 0.9867...Training: start of batch 1100; got learning rate: 0.0010000000474974513\n",
      "1200/1875 [==================>...........] - ETA: 47s - loss: 0.8782 - categorical_accuracy: 0.9869...Training: start of batch 1200; got learning rate: 0.0010000000474974513\n",
      "1300/1875 [===================>..........] - ETA: 40s - loss: 0.8780 - categorical_accuracy: 0.9871...Training: start of batch 1300; got learning rate: 0.0010000000474974513\n",
      "1400/1875 [=====================>........] - ETA: 33s - loss: 0.8779 - categorical_accuracy: 0.9871...Training: start of batch 1400; got learning rate: 0.0010000000474974513\n",
      "1500/1875 [=======================>......] - ETA: 26s - loss: 0.8778 - categorical_accuracy: 0.9872...Training: start of batch 1500; got learning rate: 0.0010000000474974513\n",
      "1600/1875 [========================>.....] - ETA: 19s - loss: 0.8776 - categorical_accuracy: 0.9874...Training: start of batch 1600; got learning rate: 0.0010000000474974513\n",
      "1700/1875 [==========================>...] - ETA: 12s - loss: 0.8776 - categorical_accuracy: 0.9873...Training: start of batch 1700; got learning rate: 0.0010000000474974513\n",
      "1800/1875 [===========================>..] - ETA: 5s - loss: 0.8775 - categorical_accuracy: 0.9873...Training: start of batch 1800; got learning rate: 0.0010000000474974513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 141s 75ms/step - loss: 0.8775 - categorical_accuracy: 0.9874 - val_loss: 0.8859 - val_categorical_accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x653cb5ad0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=5, validation_data=test_ds, callbacks=[LearningRateMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
